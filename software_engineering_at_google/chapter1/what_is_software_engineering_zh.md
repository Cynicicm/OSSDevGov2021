# 第一章

## 什么是软件工程？

> 没有什么东西是建立在石头上的；所有的东西都是建立在沙子上的，但我们必须把沙子当作石头来建造。
>
> —Jorge Luis Borges

我们认为编程和软件工程之间有三个关键性的区别：时间、规模和作用的权衡。在一个软件工程项目中，工程师需要更关注时间消耗和最终需求的改变。在软件工程组织中，我们需要更关注规模和效率，既要关注我们生产的软件，也要关注生产软件的组织。最后，作为软件工程师，通常基于对时间和增长的不精确估计，我们被要求做出更多复杂的决策，伴随着更高的风险。

在Google内部，我们有时会说：“软件工程就是随着时间的推移而整合的编程”。编程当然是软件工程的一个重要部分：毕竟，编程是你首先生成新软件的方式。如果你接受这种区分，也就清楚了，我们可能需要划分编程任务（开发）和软件工程任务（开发、修改、维护）。时间的加入给编程增加了一个重要的新维度。立方体不是正方形，距离不是速度。软件工程不是编程。

观察时间对程序影响的一种方法是思考这样一个问题：“你的代码的预期寿命是多少？”。这个问题的合理答案大约有10万倍的差异。想想需要持续几分钟的代码和想象能活几十年的代码一样合理。一般来说，处于该频谱短端的代码是不受时间影响的。你不可能为了一个实用性只有一个小时的程序而需要适应新的底层库、操作系统（OS）、硬件或语言版本。这些短命的系统实际上 “只是 ”一个编程问题，就像一个立方体在一个维度上被压缩得足够远就是一个正方形一样。当我们把这个时间扩大到允许更长的寿命时，变化变得更加重要。在十几年的时间里，大多数程序的依赖性，无论是隐性的还是显性的，都可能会发生变化。这种认识是我们区分软件工程师和编程的根本。

这种区别是我们所说的软件可持续性的核心。如果在软件的预期生命周期内，你有能力对任何有价值的变化做出反应，无论是技术上的还是商业上的，你的项目就是可持续的。重要的是，我们只关注能力——你可能会因为缺乏价值或其他优先事项而选择不执行特定的升级。当你无法对基础技术或产品方向的变化做出反应时，你就等于把高风险的赌注押在了希望这种变化永远不会成为关键。对于短期项目，这可能是一个安全的赌注。但在几十年的时间里，这可能并不安全。

另一种看待软件工程的方法是考虑规模。有多少人参与？他们在长期的开发和维护中扮演了什么角色？一个编程任务往往是个人创造的行为，但一个软件工程任务是一个团队的努力。早期对软件工程进行定义的尝试为这一观点产生了一个很好的定义：“多人开发多版本程序”。这说明软件工程与编程的区别是时间和人员的区别。团队协作带来了新的问题，但也提供了比任何一个程序员都更有可能产生有价值的系统。

团队组织、项目组成以及软件项目的政策和实践都主导着软件工程复杂性的这一方面。这些问题是规模化所固有的：随着组织的发展和项目的扩大，它在生产软件方面是否变得更有效率？我们的开发工作流程是否随着我们的成长而变得更有效率，或者我们的版本控制政策和测试策略是否让我们付出了相应的代价？围绕着沟通和人的规模问题从软件工程的早期就开始讨论了，一直可以追溯到人月神话。这样的规模问题往往是政策问题，也是软件可持续性问题的根本：我们需要重复做的事情要付出多少代价？

我们也可以说，软件工程在需要做出的决定的复杂性和其利害关系方面与编程不同。在软件工程中，我们经常被迫评估几条前进道路之间的权衡，有时风险很高，而且往往有不完善的价值衡量标准。软件工程师或软件工程领导者的工作，是为了实现组织、产品和开发工作流程的可持续性和管理扩展成本。考虑到这些投入，评估你的权衡并做出合理的决定。我们有时可能会推迟维护变化，甚至拥抱那些不能很好扩展的政策，因为我们知道我们需要重新审视这些决定。这些选择应该是明确的，并清楚地说明推迟的成本。

在软件工程中，很少有放之四海而皆准的解决方案，这本书也是如此。考虑到 ”这个软件的寿命有多长 ”的合理答案是100,000倍，”你的组织中有多少工程师 ”的范围可能是10,000倍，以及谁知道 ”你的项目有多少计算资源”，谷歌的经验可能与你的不一致。在本书中，我们旨在介绍我们在构建和维护预计将持续数十年的软件过程中所发现的有效方法，这些软件拥有数以万计的工程师和遍布全球的计算资源。我们发现在这种规模下所需要的大多数做法也会对较小的工作有很好的效果：把这看作是关于一个工程生态系统的报告，我们认为当你扩大规模时，它可能是好的。在一些地方，超大规模会带来自己的成本，而我们更乐意不支付额外的管理费。我们把这些叫出来作为一个警告。希望如果你的组织发展到足以担心这些成本，你可以找到一个更好的答案。

在我们讨论关于团队工作、文化、政策和工具的具体细节之前，让我们首先阐述一下时间、规模和权衡这些主要主题。

### 时间与变化

当一个新手在学习编程时，所产生的代码的寿命通常是以小时或天来衡量的。编程作业和练习往往是一次性写完的，几乎没有重构，当然也没有长期维护。这些程序在最初制作后往往不会再被重建或执行。这在教学环境中并不令人惊讶。也许在中学或中学后的教育中，我们可能会发现一个团队项目课程或实践论文。如果是这样的话，这样的项目很可能是学生代码活得超过一个月左右的唯一时间。这些开发者可能需要重构一些代码，也许是为了应对不断变化的需求，但他们不太可能被要求处理环境的更大变化。

在常见的行业环境中，我们也发现了短命代码的开发者。移动应用程序的寿命通常相当短，而且无论好坏，完全重写是比较常见的。早期创业公司的工程师可能会正确地选择关注眼前的目标，而不是长期投资：公司可能活得不够长，无法从回报缓慢的基础设施投资中获得收益。一个连续的初创公司的开发人员可能有10年的开发经验，但很少或根本没有维护任何预期存在超过一两年的软件的经验，这是非常合理的。

在光谱的另一端，一些成功的项目实际上具有无限制的寿命：我们不能合理地预测谷歌搜索、Linux内核或Apache HTTP服务器项目的终点。对于大多数谷歌项目，我们必须假设它们将无限期地生存下去--我们无法预测何时不需要升级我们的依赖关系、语言版本等等。随着寿命的增长，这些长寿的项目最终会有与编程作业或初创公司开发不同的感觉。

请看图1-1，它展示了两个处于 ”预期寿命 ”两端的软件项目。对于一个从事预期寿命为几个小时的任务的程序员来说，什么样的维护是合理的？也就是说，如果你在做一个将被执行一次的Python脚本时，你的操作系统出现了新的版本，你应该放弃你正在做的事情而进行升级吗？当然不是：升级并不关键。但是在光谱的另一端，谷歌搜索停留在我们的操作系统的90年代的版本上将是一个明显的问题。

![image-20210423105402808](what_is_software_engineering_zh_images/image-20210423105402808.png)

预期寿命谱上的低点和高点表明，在某个地方有一个过渡。在一个一次性项目和一个持续几十年的项目之间的某个地方，发生了一个过渡：一个项目必须开始对不断变化的外部因素作出反应。7 对于任何从一开始就没有计划升级的项目来说，这种过渡很可能是非常痛苦的，原因有三，每一个原因都会加重其他原因。

- 你正在执行一项尚未为这个项目完成的任务；更多隐藏的假设已经被烘托出来了。
- 试图进行升级的工程师不太可能有这种任务的经验。
- 升级的规模往往比平时大，一次做几年的升级，而不是更多的递增式升级。

因此，在实际经历了一次这样的升级（或中途放弃）之后，高估了后续升级的成本并决定 ”再也不升级 ”是非常合理的。得出这个结论的公司最终会承诺把东西扔掉，重写他们的代码，或者决定不再升级。与其采取自然的方法来避免一项痛苦的任务，有时更负责任的答案是投资使它不那么痛苦。这完全取决于你的升级成本，它所提供的价值，以及有关项目的预期寿命。

不仅要通过第一次大的升级，而且要达到能够可靠地保持现状的程度，这是你的项目长期可持续性的本质。可持续性需要规划和管理所需变化的影响。对于谷歌的许多项目，我们相信我们已经实现了这种可持续性，主要是通过试验和错误。

那么，具体来说，短期编程与制作预期寿命更长的代码有什么不同？随着时间的推移，我们需要更加清楚地认识到 ”碰巧能用 ”和 ”可维护 ”之间的区别。对于识别这些问题，没有完美的解决方案。这是不幸的，因为保持软件的长期可维护性是一场持久战。

### 海勒姆法则

如果你正在维护一个被其他工程师使用的项目，那么关于 ”它可以工作 ”与 ”它可以维护 ”的最重要的教训就是我们所说的海勒姆法则。

> 有了足够数量的API用户，你在合同中承诺什么并不重要：你的系统的所有可观察行为都会被某人依赖。

根据我们的经验，这个公理是任何关于随时间变化的软件的讨论中的一个主导因素。它在概念上类似于熵：讨论随时间变化和维护时必须注意到海勒姆定律8，正如讨论效率或热力学时必须注意到熵一样。熵不会减少并不意味着我们不应该努力提高效率。海勒姆定律在维护软件时也会适用，但这并不意味着我们不能对它进行规划或试图更好地理解它。我们可以减轻它，但我们知道它永远不可能被根除。

海勒姆法则代表了这样一个实际的知识：即使有最好的意图、最好的工程师和坚实的代码审查实践，我们也不能假定对已发布的合同或最佳实践的完美遵守。作为一个API的拥有者，你可以通过明确接口承诺来获得一些灵活性和自由，但是在实践中，一个特定的变化的复杂性和难度也取决于用户发现你的API的一些可观察的行为有多有用。如果用户不能依赖这样的东西，你的API就会很容易改变。如果有足够的时间和足够的用户，即使是最无害的改变也会破坏一些东西；9 你对该改变的价值的分析必须包括调查、识别和解决这些破坏的难度。

### 例子：哈希排序

考虑一下哈希迭代排序的例子。如果我们在一个基于哈希的集合中插入五个元素，我们会以什么顺序把它们取出来呢？

```python
>>> for i in {”apple”, ”banana”, ”carrot”, ”durian”, ”eggplant”}: print(i) 
...
durian
carrot
apple
eggplant
banana
```

大多数程序员都知道，哈希表是不明显的排序。很少有人知道他们所使用的特定哈希表是否打算永远提供这种特定的排序的具体情况。这可能看起来不值一提，但在过去的一二十年里，计算行业使用这种类型的经验已经发生了变化：

- 哈希泛滥攻击为非确定性的哈希迭代提供了更大的动力。
- 对改进的哈希算法或哈希容器的研究可能带来的效率提升需要改变哈希迭代顺序。
- 根据海勒姆定律，如果程序员有能力的话，他们会编写依赖于哈希表遍历顺序的程序。

因此，如果你问任何专家：”我可以为我的哈希容器假设一个特定的输出序列吗？”该专家大概会说：”不行。” 总的来说，这是正确的，但也许是简单化的。一个更细致的答案是：”如果你的代码是短期的，没有改变你的硬件、语言运行时间或数据结构的选择，这样的假设是好的。如果你不知道你的代码能活多久，或者你不能保证你所依赖的任何东西都不会改变，这样的假设是不正确的”。此外，即使你自己的实现不依赖于哈希容器的顺序，它也可能被其他代码使用，隐含地创造了这样一种依赖性。例如，如果你的库将值序列化到远程过程调用（RPC）响应中，RPC调用者可能会依赖于这些值的顺序。

这是一个非常基本的例子，说明了 ”它可以工作 ”和 ”它是正确的 ”之间的区别。对于一个短命的程序，依赖你的容器的迭代顺序不会引起任何技术问题。另一方面，对于一个软件工程项目来说，这种对定义好的顺序的依赖是一种风险--只要有足够的时间，就会有东西让你改变这个迭代顺序。这种价值可以体现在很多方面，无论是效率、安全，还是仅仅是对数据结构的未来保护，以适应未来的变化。当这种价值变得清晰时，你将需要权衡这种价值和破坏你的开发者或客户的痛苦之间的权衡。

一些语言专门在库的版本之间，甚至在同一程序的执行之间随机化哈希排序，以试图防止依赖性。但即使是这样，还是会有一些海勒姆法则的惊喜：有一些代码将哈希迭代排序作为一种低效的随机数生成器。现在去掉这种随机性会破坏这些用户。正如熵在每个热力学系统中的增加一样，海勒姆定律适用于每个可观察的行为。

仔细思考以 “现在工作 “和 “无限期工作 “的心态编写的代码之间的差异，我们可以提取一些明确的关系。把代码看作是一个具有（高度）可变寿命要求的人工制品，我们可以开始对编程风格进行分类：依赖于其依赖关系的脆弱和未公布的特征的代码可能会被描述为 “黑客 “或 “聪明“，而遵循最佳实践并对未来进行规划的代码则更可能被描述为 “干净 “和 “可维护“。两者都有各自的目的，但你选择哪一种，主要取决于相关代码的预期寿命。我们已经习惯说：“如果‘聪明‘是一种赞美，那就是编程，但如果‘聪明‘是一种指责，那就是软件工程“。

#### 为什么不以 "没有变化 "为目标？

所有这些关于时间和需要对变化做出反应的讨论都隐含着一个假设，即变化可能是必要的。是这样吗？

与本书中的其他内容一样，这看具体情况而定。我们会欣然承诺："对于大多数项目，在足够长的时间内，它们下面的一切都可能需要改变。如果你有一个用纯C语言编写的项目，没有外部依赖性（或者只有像POSIX这样承诺长期稳定的外部依赖性），你很可能能够避免任何形式的重构或困难的升级。C语言在提供稳定性方面做得很好--在许多方面，这是它的主要目的。

大多数项目在底层技术变化时遭受风险要多得多。大多数编程语言和运行时的变化比C语言要大得多。即使是用纯C语言实现的库，也可能为了支持新的功能而改变，这可能会影响到下游的用户。安全问题在各种技术中都有披露，从处理器到网络库到应用程序代码。你的项目所依赖的每一项技术都有一些（希望是小的）风险，包含关键的错误和安全漏洞，而这些问题可能在你开始依赖它之后才被发现。如果你没有能力为Heartbleed部署补丁，或减轻像Meltdown和Spectre这样的缓解投机性执行问题的话，你就是在假设（或承诺）什么都不会改变，这就是一场重大的赌博。

效率的提高使情况更加复杂。我们希 望为我们的数据中心配备高性价比的计算设备，尤其是提高CPU效率。然而，早期Google的算法和数据结构在现代设备上的效率实在是太低了：链表或二叉树仍然可以正常工作，但CPU周期与内存延迟之间不断扩大的差距影响了"高效"代码的样子。随着时间的推移，如果不对软件进行相应的设计修改，升级到新硬件的价值就会降低。向后兼容可以确保旧系统仍然可以运行，但这并不能保证旧的优化仍然有用。不愿意或不能够利用这样的机会，反而可能招致巨大的成本费用。这样的效率问题特别微妙：原来的设计可能是完全合理的，遵循合理的最佳实践。只有在经过向后兼容的变化演变之后，一个新的、更有效率的方案才变得重要。不改变并没有犯错，但时间的流逝还是让改变变得有价值。

刚才提到的，就是为什么那些没有投资于可持续性的长期项目会有很大的风险。我们必须有能力应对这类问题，利用这些机会，不管它们是直接影响我们，还是只表现为我们所建立的技术的过渡性封闭。改变并不是天生的好事。我们不应该为了改变而改变。但我们确实需要有能力去改变。如果我们考虑到这种最终的必要性，我们也应该考虑是否要投资让这种能力变得便宜。每个系统管理员都知道，在理论上知道可以从磁带上恢复是一回事，而在实践中确切地知道如何去做，以及在必要时需要花费多少钱又是另一回事。实践和专业知识是提高效率和可靠性的重要推动力。

#### 规模和效率

正如《Site Reliability Engineering》（SRE）一书中所指出的那样，Google的生产系统作为一个整体，是人类创造的最复杂的机器之一。构建这样一台机器并保持其平稳运行所涉及的复杂性，需要我们整个组织和全球的专家进行无数小时的思考、讨论和重新设计。所以，我们写了一本书，内容是保持该机器以这种规模运行的复杂性。

本书的大部分内容都集中在生产这样一台机器的组织的复杂规模，以及我们用来保持这台机器长期运行的过程。再考虑一下代码库可持续性的概念：“当你能够安全地改变所有你应该改变的东西，并且能够在你的代码库的生命周期内改变时，你的组织的代码库就是可持续的。”在关于能力的讨论中，还隐藏着一个成本问题：如果改变某件事情需要付出过高的成本，那么它很可能会被推迟。如果成本随着时间的推移超线性增长，那么这个操作显然是不可扩展的。最终，时间会占据主导地位，会出现一些你绝对必须改变的意外情况。当你的项目范围扩大一倍，你需要再次执行该任务时，是否会耗费两倍的人力？下一次你还会有所需的人力资源来解决这个问题吗？

人力成本并不是唯一需要扩展的有限资源。就像软件本身需要利用计算、内存、存储和带宽等传统资源进行良好的扩展一样，该软件的开发也需要扩展，包括人力时间的参与和为你的开发工作流提供动力的计算资源。如果你的测试集群的计算成本超线性增长，每个季度每个人消耗的计算资源更多，那么你就走在一条不可持续的道路上，需要尽快做出改变。

最后，软件组织最宝贵的资产——代码库本身也需要扩展。如果你的构建系统或版本控制系统随着时间的推移而超线性地扩展，也许是由于增长和不断增加的变更日志历史的结果，那么你可能会到了一个你根本无法继续下去的地步。很多问题，比如“做一个完整的构建需要多长时间？”、“拉一个新的版本库需要多长时间？”或者“升级到一个新的语言版本需要多少钱？”并没有被主动监控，变化的速度很慢。它们很容易变得像温水煮青蛙一样，问题很容易慢慢恶化，但永远不会表现为一个单一的危机时刻。只有全组织意识到并致力于规模化，你才有可能关注这些问题。

你的组织赖以生产和维护代码的所有东西，在总体成本和资源消耗方面应该是可扩展的。特别是，你的组织必须反复做的所有事情，在人力方面都应该是可扩展的。许多常见的策略在这个意义上似乎并不具有可扩展性。

#### 不能扩展的策略

只要稍加实践，就能更容易发现具有不良扩展属性的策略。通常，可以通过考虑对单个工程师施加的工作并想象组织将规模扩大10或100倍来确定这些问题。 当我们规模扩大10倍时，我们会不会增加10倍的工作，我们的样本工程师需要跟上？我们的工程师必须完成的工作量是否会随着组织规模的增长而增长？工作量是否会随着代码库规模的扩大而扩大？如果上述两种情况属实，我们是否有任何机制来自动化或优化这些工作？如果没有，我们就会出现扩展问题。

考虑一下传统的弃用方法。我们将在第15章中更多地讨论弃用问题，但常见的弃用方法可以作为扩展问题的一个很好的例子。一个新组件被开发出来了，然后决定大家都用新的，停止使用旧的。为了激励大家，项目负责人说：“我们将在8月15日删除旧组件，请确保你已经将原有的转换到新组件上。”

这种类型的方法在小型软件环境中可能有效，但随着依赖图的深度和广度的增加，很快就会失效。团队对组件的依赖程度越来越高，一个单一的构建中断就会以越来越大的比例影响到公司。以可扩展的方式解决这些问题意味着改变我们处理弃用问题的方式：与其将迁移工作推给客户，团队可以自己将其内部化，从而实现规模经济。

2012年，我们试图用缓解流失的规则来制止这种情况：基础设施团队必须自己动手将内部用户迁移到新版本，或者以向后兼容的方式在原地进行更新。这个被我们称为“流失规则”的政策能更好地扩展：依赖性项目不再为了跟上进度而逐渐花费更大的精力。我们还了解到，由一组专门的专家来执行变更，比要求每个用户付出更多的维护努力更有扩展性：专家们会花一些时间深入学习整个问题，然后将这些专业知识应用到每个子问题上。强迫用户应对流失意味着每个受影响的团队都会做得比专家更差，并在解决了他们眼前的问题后扔掉那些现在无用的知识。

传统的开发分支的使用是另一个有内在扩展问题的策略的例子。一个组织可能会发现，将大型功能合并到主干中已经破坏了产品的稳定性，并得出结论：“我们需要更严格地控制东西何时合并。我们应该减少合并的频率。”这很快导致每个团队或每个特性都有独立的开发分支。每当任何一个分支被决定为“完整”时，它就会被测试并合并到主干中，从而引发其他仍在其开发分支上工作的工程师的一些潜在的形式为重新同步和测试的大量工作。这样的分支管理对于小型组织，可以在5到10个这样的分支中发挥作用。但随着组织规模（以及分支数量）的增加，我们很快就会发现，为了完成同样的任务，我们付出的开销越来越大。当我们扩大规模时，我们需要一种不同的方法，我们将在第16章讨论这个问题。

#### 具有良好扩展性的策略

随着组织的发展，什么样的策略会带来更佳的成本？或者进一步，随着组织的发展，我们可以制定什么样的策略来提供超线性的价值？

我们最喜欢的内部策略之一是构建可以保护团队安全进行基础架构变更的能力，这也是基础架构团队的一大助力。“如果一个产品由于基础架构变更而出现中断或其他问题，但这个问题没有被我们的持续集成（CI）系统中的测试所覆盖到，那就不是基础架构变更的错。”更通俗地说，这句话可以被表述为“如果你喜欢它，你就应该对它进行CI测试”，即我们所称的“碧昂斯规则”(The Beyoncé Rule)13。从扩展性的角度来看，碧昂斯规则意味着：如果复杂的、一次性的定制测试不是由我们常见的CI系统触发的，则这个测试就不算数。如果没有这一点，基础设施团队的工程师可以想象，需要跟踪每一个团队的任何受影响代码，并询问他们如何运行测试。当有一百个工程师的时候，我们当然还可以做到这一点，但我们绝对不能再这样做了。

我们发现，随着组织规模的扩大，专业知识和共享交流论坛提供了巨大的价值。当工程师在共享论坛上讨论和回答问题时，知识往往会传播。新的专家也会成长起来。如果你有一百个工程师在写Java，一个愿意友好回答问题、有帮助的Java专家很快就会产生一百个写出更好Java代码的工程师。知识是病毒式的，专家是载体，这些为工程师扫除常见的绊脚石的价值是很大的。我们将在第3章中更详细地介绍这个问题。

#### 例子:编译器升级

考虑一下升级编译器这个艰巨的任务。理论上讲，考虑到语言向后兼容需要付出多少努力，编译器升级应该是很便宜的，但实际操作起来有多便宜呢？如果你从来没有做过这样的升级，你会如何评估你的代码库是否与这种变化兼容？

根据我们的经验，语言和编译器的升级是微妙而困难的任务，即使它们大体上被期望是向后兼容的。编译器升级几乎总是会导致行为的微小变化比如修复错误编译、调整优化或可能改变任何以前未定义的结果。你将如何针对所有这些潜在的结果评估整个代码库的正确性呢？

谷歌历史上最传奇的一次编译器升级发生在2006年。当时，我们已经运营了几年，有几千名工程师在职，而我们已经有大约五年没有更新编译器了，大部分工程师都没有更换编译器的经验。我们的大部分代码只经历过一个编译器版本。对于一个（大部分）由志愿者组成的团队来说，这是一项艰难而痛苦的任务。这个任务最终变成了寻找捷径和简化的问题，以便绕过我们不知道如何采用的上游编译器和语言变化。14 最终，2006年的编译器升级是非常痛苦的。许多大大小小的海拉姆定律(Hyrum's Law)问题已经潜入代码库，加深了我们对特定编译器版本的依赖性。打破这些隐性的依赖是痛苦的。有关的工程师们正在冒着风险：我们还没有碧昂斯法则，也没有一个普遍的CI系统，所以很难提前知道变化的影响，也很难确定他们不会因为回归而受到责备。

这个故事一点也不稀奇。许多公司的工程师都可以讲述一个关于痛苦的升级的类似故事。不寻常的是，我们在事后认识到这项任务是痛苦的，并开始关注技术和组织变革，以克服规模扩展问题，并将规模转化为我们的优势：自动化（使一个人可以做更多的事情），整合/一致性（使低级别的变化的问题范围有限），以及专业知识（使一些人可以做更多的事情）。

改变基础设施的频率越高，就越容易做到这一点。我们发现，大多数时候，当代码作为编译器升级等事情的一部分进行更新时，它就会变得不那么脆弱，并且在未来更容易升级。在一个生态系统中，大多数代码都经历了多次升级，它不再依赖于底层实现的细微差别，而是依赖于语言或操作系统保证的实际抽象。不管你到底要升级什么，即使控制了其他因素，预计一个代码库的第一次升级也会比以后的升级贵很多。

通过这个和其他经验，我们发现了很多影响代码库灵活性的因素。

*专业知识*

​		我们知道如何做到这一点；对于某些语言，我们现在已经在许多平台上做了数百次的编译器升级。

*稳定性*

​		由于我们更有规律地采用发布版本，因此发布版本之间的变化较小；对于一些语言，我们现在每隔一两个星期就会部署编译器升级。

*符合性*

​		没有经过升级的代码已经比较少了，这也是因为我们在定期升级。

*熟悉度*

​		由于我们经常这样做，我们可以在执行升级的过程中发现冗余，并尝试自动化。这与SRE关于辛苦工作的观点有很大的重合。

*政策*

​		我们有像碧昂丝规则这样的流程和政策。这些流程的净效果是，升级仍然是可行的，因为基础设施团队不需要担心每一个未知的使用，只需要担心我们CI系统中可见的使用。



根本的教训不是关于编译器升级的频率或难度，而是当我们意识到编译器升级任务是必要的时候，我们就想方设法确保用恒定数量的工程师来执行这些任务，即使代码库随着增长。16 如果我们反而认为这项任务太昂贵，今后应该避免，我们可能还在使用一个十年前的编译器版本。由于错过了优化机会，我们可能要为计算资源多付25%的费用。鉴于2006年时代的编译器肯定无助于缓解投机性执行漏洞，我们的中央基础设施可能会受到重大安全风险的影响。停滞不前是一种选择，但往往不是明智之举。